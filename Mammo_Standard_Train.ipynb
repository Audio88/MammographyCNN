{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import models, layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly intialized CNN\n",
    "\n",
    "This model was mostly for educational purposes. I learned a lot about different kinds of layers like: Batch normalization, max pooling, Drop out, and basic Convolutional layers. During my experimenting with different CNN architectures I did not train the models for longer then ten hours. I learned how much training time these models need, often way more than ten hours. After my experimentation with these architectures I realized just how important learning rate was. Something I did not investigate for a while, but realize now that this is an important parameter to train these neural networks from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loops through ImageDataGenerator and grabs true labels and predictions\n",
    "#and reports metrics with classification_report method\n",
    "def predict_and_report(gen, model):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    gen.reset()\n",
    "    for img, label in gen:\n",
    "        #get true labels for batch and store them\n",
    "        y_true.extend([int(z[1]) for z in label])\n",
    "        #Get predictions as probabilities\n",
    "        batch_pred = model.predict_on_batch(img)\n",
    "        #turn probabilities to class labels and store\n",
    "        batch_pred = np.argmax(batch_pred, axis=1)\n",
    "        y_pred.extend(batch_pred)\n",
    "        #break loop\n",
    "        if gen.batch_index == 0:\n",
    "            break\n",
    "            \n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39011 images belonging to 2 classes.\n",
      "Found 8436 images belonging to 2 classes.\n",
      "Found 8438 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'C:\\\\users\\\\will\\\\ds\\\\mammo\\\\train'\n",
    "valid_dir = 'C:\\\\users\\\\will\\\\ds\\\\mammo\\\\validation'\n",
    "test_dir = 'C:\\\\users\\\\will\\\\ds\\\\mammo\\\\test'\n",
    "\n",
    "img_width, img_height = 299, 299\n",
    "batch_size = 64\n",
    "num_epochs = 160\n",
    "filter_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "drop_out_dense = 0.5\n",
    "drop_out_conv = 0.25\n",
    "padding = 'same'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 299, 299, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 299, 299, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 149, 149, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 149, 149, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 149, 149, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 149, 149, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 74, 74, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 74, 74, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 74, 74, 96)        55392     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 74, 74, 96)        83040     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 37, 37, 96)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37, 37, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 37, 37, 128)       110720    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 37, 37, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               21234176  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 21,761,826\n",
      "Trainable params: 21,761,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=filter_size, activation='relu', input_shape=(img_width, img_height, 1), padding=padding))\n",
    "model.add(Conv2D(32, kernel_size=filter_size, activation='relu', padding=padding))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(drop_out_conv))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=filter_size, activation='relu', padding=padding))\n",
    "model.add(Conv2D(64, kernel_size=filter_size, activation='relu', padding=padding))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(drop_out_conv))\n",
    "\n",
    "model.add(Conv2D(96, kernel_size=filter_size, activation='relu', padding=padding))\n",
    "model.add(Conv2D(96, kernel_size=filter_size, activation='relu', padding=padding))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(drop_out_conv))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=filter_size, activation='relu', padding=padding))\n",
    "model.add(Conv2D(128, kernel_size=filter_size, activation='relu', padding=padding))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(drop_out_conv))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(drop_out_dense))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(drop_out_dense))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "610/610 [==============================] - 212s 347ms/step - loss: 0.1131 - acc: 0.7321 - val_loss: 0.3352 - val_acc: 0.7979\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Save best model\n",
    "filepath=\"C:\\\\users\\\\will\\\\ds\\\\mammo-weights\\\\weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "#Lost the training output for this model, but the weights were saved\n",
    "model.load_weights(r'C:\\Users\\Will\\ds\\mammo-weights-8layer160\\weights-improvement-154-0.91.hdf5')\n",
    "\n",
    "result = model.fit_generator(\n",
    "            train_generator,\n",
    "            epochs=num_epochs,\n",
    "            verbose = 1,\n",
    "            class_weight= {0:.13, 1:.87},\n",
    "            callbacks=callbacks_list,\n",
    "            validation_data = validation_generator\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.94      0.95      7343\n",
      "          1       0.64      0.67      0.66      1093\n",
      "\n",
      "avg / total       0.91      0.91      0.91      8436\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.94      0.95     33909\n",
      "          1       0.63      0.68      0.65      5102\n",
      "\n",
      "avg / total       0.91      0.91      0.91     39011\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(r'C:\\Users\\Will\\ds\\mammo-weights-8layer160\\weights-improvement-154-0.91.hdf5')\n",
    "predict_and_report(validation_generator, model)\n",
    "predict_and_report(train_generator, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
